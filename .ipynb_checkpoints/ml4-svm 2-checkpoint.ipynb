{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import numpy as np\n",
    "\n",
    "style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Support_Vector_Machine:\n",
    "    def __init__(self, visualization=True):\n",
    "        # se empieza a crear el grafico\n",
    "        self.visualization = visualization\n",
    "        self.colors = {1:'r',-1:'b'}\n",
    "        if self.visualization:\n",
    "            self.fig = plt.figure()\n",
    "            self.ax = self.fig.add_subplot(1,1,1)\n",
    "            #self.fig.show()\n",
    "    \n",
    "    # train\n",
    "    def fit(self, data):\n",
    "        print(\"data:\",data)\n",
    "        self.data = data\n",
    "        # { ||w||: [w,b] }\n",
    "        opt_dict = {}\n",
    "\n",
    "        transforms = [[1,1],\n",
    "                      [-1,1],\n",
    "                      [-1,-1],\n",
    "                      [1,-1]]\n",
    "        print(\"############################### 1 ##\")\n",
    "        # finding values to work with for our ranges.\n",
    "        all_data = [] #esto va almacenar todos los datos de las X del dataset\n",
    "        for yi in self.data: #for labels in dataset\n",
    "            print(\"----------------------\")\n",
    "            print(\"label y:\",yi)\n",
    "            print(\"----------------------\")\n",
    "            for featureset in self.data[yi]: #for vector x in dataset\n",
    "                print(\"featureset:\",featureset)\n",
    "                for feature in featureset: #for x in vector x\n",
    "                    all_data.append(feature)\n",
    "        print(\"\\nall_data:\",all_data)\n",
    "        print(\"############################### 2 ##\")\n",
    "        # oá¹•tendremos el valor maximo y minimo del dataset\n",
    "        self.max_feature_value = max(all_data)\n",
    "        self.min_feature_value = min(all_data)\n",
    "        print(\"max_feature_value:\",self.max_feature_value)\n",
    "        print(\"min_feature_value:\",self.min_feature_value)\n",
    "        # no need to keep this memory.\n",
    "        all_data=None\n",
    "        \n",
    "        # step_sizes son los learning rate para w\n",
    "        step_sizes = [self.max_feature_value * 0.1, \n",
    "                      self.max_feature_value * 0.01,\n",
    "                      #point of expense\n",
    "                      self.max_feature_value * 0.001] # starts getting very high cost after this.\n",
    "        print(\"step_sizes:\",step_sizes)\n",
    "        \n",
    "        #learning rate para b\n",
    "        # extremely expensive\n",
    "        b_range_multiple = 5\n",
    "        b_multiple = 5\n",
    "        latest_optimum = self.max_feature_value*10 #primer valor de w\n",
    "        print(\"############################################ 3 ##\")\n",
    "        \n",
    "        for step in step_sizes: #por cada learning rate de w\n",
    "            print(\"---------------------------\")\n",
    "            print(\"step:\", step)\n",
    "            print(\"---------------------------\")\n",
    "            w = np.array([latest_optimum,latest_optimum]) #crea el vector w usando el valor max * 10 en ambas dimenciones\n",
    "            print(\"w:\",w)\n",
    "            # we can do this because convex\n",
    "            optimized = False\n",
    "            print(\" ############################### b\")\n",
    "            print(\"   b range: \",-1*(self.max_feature_value*b_range_multiple),\"-\",(self.max_feature_value*b_range_multiple))\n",
    "            while not optimized:\n",
    "                for b in np.arange(-1*(self.max_feature_value*b_range_multiple),\n",
    "                                   self.max_feature_value*b_range_multiple,\n",
    "                                   step*b_multiple):\n",
    "                    #print(\"**********************\")\n",
    "                    #print(\"**********************\")\n",
    "                    #print(\"b\",b)\n",
    "                    #print(\"******************\")\n",
    "                    #print(\"**********************\")\n",
    "                    for transformation in transforms: #por cada forma posible de cada w\n",
    "                        #print(\"||||||||||||||||||||||\")\n",
    "                        #print(\"transformation\", transformation)\n",
    "                        w_t = w*transformation # w multiplicado por la tranformacion\n",
    "                        #print(\"w_t\", w_t)\n",
    "                        #print(\"----------------------\")\n",
    "                        found_option = True\n",
    "                        # weakest link in the SVM fundamentally\n",
    "                        # SMO attempts to fix this a bit\n",
    "                        # yi(xi.w+b) >= 1\n",
    "                        # \n",
    "                        # #### add a break here later..\n",
    "                        for i in self.data: # por cada label en el dataset\n",
    "                            #print(\"i:\",i)\n",
    "                            for xi in self.data[i]: # por cada vector de x en el dataset\n",
    "                                #print(\"-----------------\")\n",
    "                                #print(\"xi:\",xi)\n",
    "                                yi=i # etiqueda de y del vector actual de x\n",
    "                                if not yi*(np.dot(w_t,xi)+b) >= 1:\n",
    "                                    #print(\"no es >=1\")\n",
    "                                    found_option = False\n",
    "                                #else:\n",
    "                                    #print(\"si es >=1\")\n",
    "                                    \n",
    "                        if found_option:\n",
    "                            # np.linalg.norm(w_t) devuelve la amgnitud del vector\n",
    "                            opt_dict[np.linalg.norm(w_t)] = [w_t,b] # si esto if not yi*(np.dot(w_t,xi)+b) >= 1: no se cumple se entra aqui\n",
    "                            #print(\"opt_dict:\",opt_dict)\n",
    "                if w[0] < 0:\n",
    "                    optimized = True\n",
    "                    print('Optimized a step.')\n",
    "                else:\n",
    "                    w = w - step\n",
    "                    \n",
    "            print(\"##################\")\n",
    "            #print(\"opt_dict:\",opt_dict)\n",
    "            #print(\"[n for n in opt_dict]:\",[n for n in opt_dict])\n",
    "            print(\"##################\")\n",
    "            norms = sorted([n for n in opt_dict]) # se guardan en esta lista todos los keys de opt_dict que son w_t\n",
    "                                                  # en orden ascendente\n",
    "            #||w|| : [w,b]\n",
    "            print(\"norms:\",norms)\n",
    "            print(\"norms[0]\", norms[0])\n",
    "            opt_choice = opt_dict[norms[0]] # se guarda el contenido de opt_dict donde la key es menor\n",
    "            print(\"opt_choice:\",opt_choice)\n",
    "            self.w = opt_choice[0] # se guarda el vector w_t con menor magnitud\n",
    "            self.b = opt_choice[1] # se guarda el b donde se cumplio el requizito de found_option\n",
    "            latest_optimum = opt_choice[0][0]+step*2\n",
    "            \n",
    "    def predict(self,features):\n",
    "        # classifiction is just:\n",
    "        # sign(xi.w+b)\n",
    "        classification = np.sign(np.dot(np.array(features),self.w)+self.b)\n",
    "        # if the classification isn't zero, and we have visualization on, we graph\n",
    "        if classification != 0 and self.visualization:\n",
    "            self.ax.scatter(features[0],features[1],s=200,marker='*', c=self.colors[classification])\n",
    "        else:\n",
    "            print('featureset',features,'is on the decision boundary')\n",
    "        return classification\n",
    "    \n",
    "    def visualize(self):\n",
    "        #scattering known featuresets.\n",
    "        [[self.ax.scatter(x[0],x[1],s=100,color=self.colors[i]) for x in data_dict[i]] for i in data_dict]\n",
    "        \n",
    "        # hyperplane = x.w+b\n",
    "        # v = x.w+b\n",
    "        # psv = 1\n",
    "        # nsv = -1\n",
    "        # dec = 0\n",
    "        def hyperplane(x,w,b,v):\n",
    "            return (-w[0]*x-b+v) / w[1]\n",
    "        \n",
    "        datarange = (self.min_feature_value*0.9,self.max_feature_value*1.1)\n",
    "        hyp_x_min = datarange[0]\n",
    "        hyp_x_max = datarange[1]\n",
    "        \n",
    "        # w.x + b = 1\n",
    "        # pos sv hyperplane\n",
    "        psv1 = hyperplane(hyp_x_min, self.w, self.b, 1)\n",
    "        psv2 = hyperplane(hyp_x_max, self.w, self.b, 1)\n",
    "        self.ax.plot([hyp_x_min,hyp_x_max], [psv1,psv2], \"k\")\n",
    "        \n",
    "        # w.x + b = -1\n",
    "        # negative sv hyperplane\n",
    "        nsv1 = hyperplane(hyp_x_min, self.w, self.b, -1)\n",
    "        nsv2 = hyperplane(hyp_x_max, self.w, self.b, -1)\n",
    "        self.ax.plot([hyp_x_min,hyp_x_max], [nsv1,nsv2], \"k\")\n",
    "\n",
    "        # w.x + b = 0\n",
    "        # decision\n",
    "        db1 = hyperplane(hyp_x_min, self.w, self.b, 0)\n",
    "        db2 = hyperplane(hyp_x_max, self.w, self.b, 0)\n",
    "        self.ax.plot([hyp_x_min,hyp_x_max], [db1,db2], \"g--\")\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {-1:np.array([[1,7],\n",
    "                          [2,8],\n",
    "                          [3,8],]),\n",
    "             \n",
    "             1:np.array([[5,1],\n",
    "                         [6,-1],\n",
    "                         [7,3],])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: {-1: array([[1, 7],\n",
      "       [2, 8],\n",
      "       [3, 8]]), 1: array([[ 5,  1],\n",
      "       [ 6, -1],\n",
      "       [ 7,  3]])}\n",
      "############################### 1 ##\n",
      "----------------------\n",
      "label y: -1\n",
      "----------------------\n",
      "featureset: [1 7]\n",
      "featureset: [2 8]\n",
      "featureset: [3 8]\n",
      "----------------------\n",
      "label y: 1\n",
      "----------------------\n",
      "featureset: [5 1]\n",
      "featureset: [ 6 -1]\n",
      "featureset: [7 3]\n",
      "\n",
      "all_data: [1, 7, 2, 8, 3, 8, 5, 1, 6, -1, 7, 3]\n",
      "############################### 2 ##\n",
      "max_feature_value: 8\n",
      "min_feature_value: -1\n",
      "step_sizes: [0.8, 0.08, 0.008]\n",
      "############################################ 3 ##\n",
      "---------------------------\n",
      "step: 0.8\n",
      "---------------------------\n",
      "w: [80 80]\n",
      " ############################### b\n",
      "   b range:  -40 - 40\n",
      "Optimized a step.\n",
      "##################\n",
      "##################\n",
      "norms: [1.1313708498982635, 1.1313708498986887, 2.2627416997971648, 3.394112549695641, 4.525483399594116, 5.656854249492593, 6.788225099391068, 7.919595949289544, 9.05096679918802, 10.182337649086495, 11.31370849898497, 12.445079348883448, 13.576450198781925, 14.707821048680403, 15.83919189857888, 16.970562748477356, 18.101933598375833, 19.23330444827431, 20.364675298172788, 21.496046148071265, 22.627416997969743, 23.75878784786822, 24.890158697766697, 26.021529547665175, 27.152900397563652, 28.28427124746213, 29.415642097360603, 30.54701294725908, 31.678383797157558, 32.80975464705603, 33.94112549695451, 35.07249634685299, 36.20386719675147, 37.33523804664995, 38.46660889654842, 39.597979746446896, 40.72935059634537, 41.86072144624385, 42.99209229614233, 44.123463146040805, 45.254833995939286, 46.38620484583775, 47.51757569573623, 48.64894654563469, 49.78031739553317, 50.91168824543165, 52.043059095330115, 53.17442994522859, 54.305800795127055, 55.437171645025536, 56.568542494924, 57.69991334482248, 58.83128419472094, 59.96265504461942, 61.09402589451789, 62.225396744416365, 63.35676759431483, 64.4881384442133, 65.61950929411178, 66.75088014401025, 67.88225099390873, 69.0136218438072, 70.14499269370567, 71.27636354360415, 72.40773439350261, 73.53910524340108, 74.67047609329956, 75.80184694319803, 76.9332177930965, 78.06458864299496, 79.19595949289344, 80.32733034279191, 81.45870119269038, 82.59007204258886, 83.72144289248733, 84.8528137423858, 85.98418459228428, 87.11555544218275, 88.24692629208123, 89.37829714197969, 90.50966799187816, 91.64103884177663, 92.77240969167511, 93.90378054157358, 95.03515139147206, 96.16652224137052, 97.29789309126899, 98.42926394116746, 99.56063479106594, 100.69200564096441, 101.82337649086288, 102.95474734076136, 104.08611819065983, 105.2174890405583, 106.34885989045678, 107.48023074035524, 108.61160159025371, 109.74297244015219, 110.87434329005066, 112.00571413994913, 113.13708498984761]\n",
      "norms[0] 1.1313708498982635\n",
      "opt_choice: [array([ 0.8, -0.8]), 0.0]\n",
      "---------------------------\n",
      "step: 0.08\n",
      "---------------------------\n",
      "w: [2.4 2.4]\n",
      " ############################### b\n",
      "   b range:  -40 - 40\n",
      "Optimized a step.\n",
      "##################\n",
      "##################\n",
      "norms: [0.4525483399591766, 0.5656854249490242, 0.6788225099388718, 0.7919595949287195, 0.905096679918567, 1.0182337649084146, 1.1313708498982622, 1.1313708498982635, 1.1313708498986887, 1.2445079348881096, 1.3576450198779573, 1.4707821048678047, 1.5839191898576526, 1.6970562748475002, 1.8101933598373479, 1.9233304448271955, 2.036467529817043, 2.1496046148068912, 2.262741699796739, 2.2627416997971648, 2.3758787847865865, 2.489015869776434, 2.602152954766282, 2.7152900397561295, 2.828427124745977, 2.9415642097358248, 3.0547012947256724, 3.1678383797155205, 3.2809754647053677, 3.394112549695216, 3.394112549695641, 4.525483399594116, 5.656854249492593, 6.788225099391068, 7.919595949289544, 9.05096679918802, 10.182337649086495, 11.31370849898497, 12.445079348883448, 13.576450198781925, 14.707821048680403, 15.83919189857888, 16.970562748477356, 18.101933598375833, 19.23330444827431, 20.364675298172788, 21.496046148071265, 22.627416997969743, 23.75878784786822, 24.890158697766697, 26.021529547665175, 27.152900397563652, 28.28427124746213, 29.415642097360603, 30.54701294725908, 31.678383797157558, 32.80975464705603, 33.94112549695451, 35.07249634685299, 36.20386719675147, 37.33523804664995, 38.46660889654842, 39.597979746446896, 40.72935059634537, 41.86072144624385, 42.99209229614233, 44.123463146040805, 45.254833995939286, 46.38620484583775, 47.51757569573623, 48.64894654563469, 49.78031739553317, 50.91168824543165, 52.043059095330115, 53.17442994522859, 54.305800795127055, 55.437171645025536, 56.568542494924, 57.69991334482248, 58.83128419472094, 59.96265504461942, 61.09402589451789, 62.225396744416365, 63.35676759431483, 64.4881384442133, 65.61950929411178, 66.75088014401025, 67.88225099390873, 69.0136218438072, 70.14499269370567, 71.27636354360415, 72.40773439350261, 73.53910524340108, 74.67047609329956, 75.80184694319803, 76.9332177930965, 78.06458864299496, 79.19595949289344, 80.32733034279191, 81.45870119269038, 82.59007204258886, 83.72144289248733, 84.8528137423858, 85.98418459228428, 87.11555544218275, 88.24692629208123, 89.37829714197969, 90.50966799187816, 91.64103884177663, 92.77240969167511, 93.90378054157358, 95.03515139147206, 96.16652224137052, 97.29789309126899, 98.42926394116746, 99.56063479106594, 100.69200564096441, 101.82337649086288, 102.95474734076136, 104.08611819065983, 105.2174890405583, 106.34885989045678, 107.48023074035524, 108.61160159025371, 109.74297244015219, 110.87434329005066, 112.00571413994913, 113.13708498984761]\n",
      "norms[0] 0.4525483399591766\n",
      "opt_choice: [array([ 0.32, -0.32]), 0.39999999999985647]\n",
      "---------------------------\n",
      "step: 0.008\n",
      "---------------------------\n",
      "w: [0.48 0.48]\n",
      " ############################### b\n",
      "   b range:  -40 - 40\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-3078e0eaaf78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSupport_Vector_Machine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m predict_us = [[0,10],\n\u001b[1;32m      5\u001b[0m               \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-afec5d9c5c9f>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     88\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# por cada label en el dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                             \u001b[0;31m#print(\"i:\",i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                             \u001b[0;32mfor\u001b[0m \u001b[0mxi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# por cada vector de x en el dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m                                 \u001b[0;31m#print(\"-----------------\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                                 \u001b[0;31m#print(\"xi:\",xi)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "svm = Support_Vector_Machine()\n",
    "svm.fit(data=data_dict)\n",
    "\n",
    "predict_us = [[0,10],\n",
    "              [1,3],\n",
    "              [3,4],\n",
    "              [3,5],\n",
    "              [5,5],\n",
    "              [5,6],\n",
    "              [6,-5],\n",
    "              [5,8]]\n",
    "\n",
    "for p in predict_us:\n",
    "    svm.predict(p)\n",
    "\n",
    "svm.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "444444444444\n"
     ]
    }
   ],
   "source": [
    "print(444444444444)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
