{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import numpy as np\n",
    "\n",
    "style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Support_Vector_Machine:\n",
    "    def __init__(self, visualization=True):\n",
    "        # se empieza a crear el grafico\n",
    "        self.visualization = visualization\n",
    "        self.colors = {1:'r',-1:'b'}\n",
    "        if self.visualization:\n",
    "            self.fig = plt.figure()\n",
    "            self.ax = self.fig.add_subplot(1,1,1)\n",
    "            #self.fig.show()\n",
    "    \n",
    "    # train\n",
    "    def fit(self, data):\n",
    "        print(\"data:\",data)\n",
    "        self.data = data\n",
    "        # { ||w||: [w,b] }\n",
    "        opt_dict = {}\n",
    "\n",
    "        transforms = [[1,1],\n",
    "                      [-1,1],\n",
    "                      [-1,-1],\n",
    "                      [1,-1]]\n",
    "        print(\"############################### 1 ##\")\n",
    "        # finding values to work with for our ranges.\n",
    "        all_data = [] #esto va almacenar todos los datos de las X del dataset\n",
    "        for yi in self.data: #for labels in dataset\n",
    "            print(\"----------------------\")\n",
    "            print(\"label y:\",yi)\n",
    "            print(\"----------------------\")\n",
    "            for featureset in self.data[yi]: #for vector x in dataset\n",
    "                print(\"featureset:\",featureset)\n",
    "                for feature in featureset: #for x in vector x\n",
    "                    all_data.append(feature)\n",
    "        print(\"\\nall_data:\",all_data)\n",
    "        print(\"############################### 2 ##\")\n",
    "        # oá¹•tendremos el valor maximo y minimo del dataset\n",
    "        self.max_feature_value = max(all_data)\n",
    "        self.min_feature_value = min(all_data)\n",
    "        print(\"max_feature_value:\",self.max_feature_value)\n",
    "        print(\"min_feature_value:\",self.min_feature_value)\n",
    "        # no need to keep this memory.\n",
    "        all_data=None\n",
    "        \n",
    "        # step_sizes son los learning rate para w\n",
    "        step_sizes = [self.max_feature_value * 0.1, \n",
    "                      self.max_feature_value * 0.01,\n",
    "                      #point of expense\n",
    "                      self.max_feature_value * 0.001] # starts getting very high cost after this.\n",
    "        print(\"step_sizes:\",step_sizes)\n",
    "        \n",
    "        #learning rate para b\n",
    "        # extremely expensive\n",
    "        b_range_multiple = 5\n",
    "        b_multiple = 5\n",
    "        latest_optimum = self.max_feature_value*10 #primer valor de w\n",
    "        print(\"############################################ 3 ##\")\n",
    "        \n",
    "        for step in step_sizes: #por cada learning rate de w\n",
    "            print(\"---------------------------\")\n",
    "            print(\"step:\", step)\n",
    "            print(\"---------------------------\")\n",
    "            w = np.array([latest_optimum,latest_optimum]) #crea el vector w usando el valor max * 10 en ambas dimenciones\n",
    "            print(\"w:\",w)\n",
    "            # we can do this because convex\n",
    "            optimized = False\n",
    "            print(\" ############################### b\")\n",
    "            print(\"   b range: \",-1*(self.max_feature_value*b_range_multiple),\"-\",(self.max_feature_value*b_range_multiple))\n",
    "            while not optimized:\n",
    "                for b in np.arange(-1*(self.max_feature_value*b_range_multiple),\n",
    "                                   self.max_feature_value*b_range_multiple,\n",
    "                                   step*b_multiple):\n",
    "                    print(\"**********************\")\n",
    "                    print(\"**********************\")\n",
    "                    print(\"b\",b)\n",
    "                    print(\"******************\")\n",
    "                    print(\"**********************\")\n",
    "                    for transformation in transforms: #por cada forma posible de cada w\n",
    "                        print(\"||||||||||||||||||||||\")\n",
    "                        print(\"transformation\", transformation)\n",
    "                        w_t = w*transformation # w multiplicado por la tranformacion\n",
    "                        print(\"w_t\", w_t)\n",
    "                        print(\"----------------------\")\n",
    "                        found_option = True\n",
    "                        # weakest link in the SVM fundamentally\n",
    "                        # SMO attempts to fix this a bit\n",
    "                        # yi(xi.w+b) >= 1\n",
    "                        # \n",
    "                        # #### add a break here later..\n",
    "                        for i in self.data: # por cada label en el dataset\n",
    "                            print(\"i:\",i)\n",
    "                            for xi in self.data[i]: # por cada vector de x en el dataset\n",
    "                                print(\"-----------------\")\n",
    "                                print(\"xi:\",xi)\n",
    "                                yi=i # etiqueda de y del vector actual de x\n",
    "                                if not yi*(np.dot(w_t,xi)+b) >= 1:\n",
    "                                    print(\"no es >=1\")\n",
    "                                    found_option = False\n",
    "                                else:\n",
    "                                    print(\"si es >=1\")\n",
    "                                    \n",
    "                        if found_option:\n",
    "                            # np.linalg.norm(w_t) devuelve la amgnitud del vector\n",
    "                            opt_dict[np.linalg.norm(w_t)] = [w_t,b]\n",
    "                            print(\"opt_dict:\",opt_dict)\n",
    "                if w[0] < 0:\n",
    "                    optimized = True\n",
    "                    print('Optimized a step.')\n",
    "                else:\n",
    "                    w = w - step\n",
    "\n",
    "            norms = sorted([n for n in opt_dict])\n",
    "            #||w|| : [w,b]\n",
    "            opt_choice = opt_dict[norms[0]]\n",
    "            self.w = opt_choice[0]\n",
    "            self.b = opt_choice[1]\n",
    "            latest_optimum = opt_choice[0][0]+step*2\n",
    "            \n",
    "    def predict(self,features):\n",
    "        # classifiction is just:\n",
    "        # sign(xi.w+b)\n",
    "        classification = np.sign(np.dot(np.array(features),self.w)+self.b)\n",
    "        # if the classification isn't zero, and we have visualization on, we graph\n",
    "        if classification != 0 and self.visualization:\n",
    "            self.ax.scatter(features[0],features[1],s=200,marker='*', c=self.colors[classification])\n",
    "        else:\n",
    "            print('featureset',features,'is on the decision boundary')\n",
    "        return classification\n",
    "    \n",
    "    def visualize(self):\n",
    "        #scattering known featuresets.\n",
    "        [[self.ax.scatter(x[0],x[1],s=100,color=self.colors[i]) for x in data_dict[i]] for i in data_dict]\n",
    "        \n",
    "        # hyperplane = x.w+b\n",
    "        # v = x.w+b\n",
    "        # psv = 1\n",
    "        # nsv = -1\n",
    "        # dec = 0\n",
    "        def hyperplane(x,w,b,v):\n",
    "            return (-w[0]*x-b+v) / w[1]\n",
    "        \n",
    "        datarange = (self.min_feature_value*0.9,self.max_feature_value*1.1)\n",
    "        hyp_x_min = datarange[0]\n",
    "        hyp_x_max = datarange[1]\n",
    "        \n",
    "        # w.x + b = 1\n",
    "        # pos sv hyperplane\n",
    "        psv1 = hyperplane(hyp_x_min, self.w, self.b, 1)\n",
    "        psv2 = hyperplane(hyp_x_max, self.w, self.b, 1)\n",
    "        self.ax.plot([hyp_x_min,hyp_x_max], [psv1,psv2], \"k\")\n",
    "        \n",
    "        # w.x + b = -1\n",
    "        # negative sv hyperplane\n",
    "        nsv1 = hyperplane(hyp_x_min, self.w, self.b, -1)\n",
    "        nsv2 = hyperplane(hyp_x_max, self.w, self.b, -1)\n",
    "        self.ax.plot([hyp_x_min,hyp_x_max], [nsv1,nsv2], \"k\")\n",
    "\n",
    "        # w.x + b = 0\n",
    "        # decision\n",
    "        db1 = hyperplane(hyp_x_min, self.w, self.b, 0)\n",
    "        db2 = hyperplane(hyp_x_max, self.w, self.b, 0)\n",
    "        self.ax.plot([hyp_x_min,hyp_x_max], [db1,db2], \"g--\")\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {-1:np.array([[1,7],\n",
    "                          [2,8],\n",
    "                          [3,8],]),\n",
    "             \n",
    "             1:np.array([[5,1],\n",
    "                         [6,-1],\n",
    "                         [7,3],])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = Support_Vector_Machine()\n",
    "svm.fit(data=data_dict)\n",
    "\n",
    "predict_us = [[0,10],\n",
    "              [1,3],\n",
    "              [3,4],\n",
    "              [3,5],\n",
    "              [5,5],\n",
    "              [5,6],\n",
    "              [6,-5],\n",
    "              [5,8]]\n",
    "\n",
    "for p in predict_us:\n",
    "    svm.predict(p)\n",
    "\n",
    "svm.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(444444444444)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
